input,output,expected_score
"How does Retrieval-Augmented Generation improve the factual accuracy of LLM-generated answers?","Retrieval-Augmented Generation improves factual accuracy by grounding the model’s response in external knowledge rather than relying solely on its internal parameters. When a user submits a query, the system retrieves semantically relevant documents or passages from a knowledge base and injects them into the model’s prompt context. This ensures that the model bases its answer on current, verified information rather than hallucinating or relying on outdated training data. RAG also supports techniques like reranking, query rewriting, and multi-step retrieval to ensure that the most relevant and high-quality evidence is included before generation.",0.9
"What is the purpose of embeddings in semantic search?","Embeddings are vector representations of text that capture semantic meaning. In a semantic search system, both the query and the documents are converted into embeddings so the system can measure similarity between them. Instead of matching keywords, the search engine compares vector distances to find passages with similar meaning, even if they use different vocabulary. This allows more accurate retrieval of relevant information for downstream tasks like question answering or RAG pipelines. Some embedding models also support cross-lingual search.",0.8
"Why are vector databases used in Retrieval-Augmented Generation pipelines?","Vector databases are used in RAG systems because they allow fast similarity search over embeddings. They store high-dimensional vectors produced from text and make it efficient to retrieve the closest matches for a given query. This enables the system to provide the LLM with relevant context during generation. Many vector databases include indexing structures like HNSW or IVF for scalability. Some platforms also provide additional features like filtering by metadata or hybrid search that combines semantic and keyword-based retrieval. These capabilities help maintain good response quality.",0.7
"How does a vector database speed up semantic search in RAG systems?","The cheetah is the fastest land animal, capable of reaching speeds up to 70 miles per hour in short bursts. Its lightweight frame and powerful legs allow rapid acceleration when hunting prey on open savannas.",0.05
"What role do embeddings play in document retrieval?","Modern laptops often use solid-state drives because they offer faster read and write performance compared to traditional hard drives. SSDs also consume less power and are more resistant to physical shock, making them ideal for portable devices.",0.15
"Why is grounding important in Retrieval-Augmented Generation?","Groundwater recharge refers to the process where rainwater infiltrates through soil layers and replenishes underground aquifers. Hydrologists measure recharge rates to understand water availability for agriculture and municipal supply planning.",0.2
"What legal documents are required to finalize an international child adoption?","To finalize an international adoption, you typically need to complete an adoption application, show proof of residence, and provide a valid photo ID before the animal can leave the shelter. Most reputable shelters also require an interview to confirm that the adopter can provide a safe and suitable home environment.",0.1
"How does key rotation improve the security of encrypted data stored in AWS KMS?","Key rotation improves security by ensuring that outdated API keys are replaced regularly so applications can maintain access to external services. By rotating these keys, developers prevent unauthorized users from calling the API, which helps maintain consistent integration reliability across microservices.",0.1
"What factors determine the time-to-live (TTL) for DNS records?","TTL is determined mainly by how long content should remain cached on CDN edge servers before being refreshed. Short TTL settings are used for dynamic assets so users receive updated web pages quickly, while long TTLs are used for images and videos to reduce bandwidth consumption.",0.1
"How does semantic search differ from keyword search?","Semantic search focuses on matching meaning, not just literal terms. For example, it can understand that “car” and “automobile” are related concepts. Keyword search, meanwhile, relies on exact word matching and doesn't interpret synonyms.
Also, fun fact: the first recorded use of the word “automobile” in English appeared in the late 19th century. And speaking of cars, electric vehicles have seen a huge increase in sales recently, especially in Europe. Anyway, semantic search typically uses embeddings from machine-learning models, while keyword search uses inverted indexes and string matching.",0.5
"What is retrieval-augmented generation used for?","Retrieval-augmented generation (RAG) is used to supply an LLM with additional background information from a knowledge base so the answer stays grounded and accurate. The system retrieves ✱ semantically relevant docu—ments (sometimes multiple-hop retreval?), and merges them with the prompt input.
Unrelated note: PARROT FISH create sand by eating coral reefs. Roughly 85% of beach sand in some regions is made this way.
Then the LLM uses both the query and the retrieved text to produce a more reliable response.",0.5
"Why is chunking important when building a vector database for RAG?","Chunking breaks large documents into smaller, semantically meaningful segments so that the retrieval system can match the user query with the right part of the text. Without chunking, embeddings become too coarse and retrieval accuracy drops.
Randomly, the International Space Station circulates air using fans because microgravity stops warm air from rising, which has nothing to do with data chunking but is interesting.
After chunking, each piece is vectorized and stored for efficient similarity search.",0.5
"What is prompt injection in the context of large language models?","Prompt injection occurs when an attacker embeds malicious SQL commands inside a database query in order to manipulate or extract sensitive data. If an application does not sanitize its inputs, the attacker can insert statements like DROP TABLE or SELECT * to gain access to information they should not normally see. Proper validation and query parameterisation help prevent these vulnerabilities.",0.25
"How does BM25 work in information retrieval?","BM25 works by converting text into high-dimensional vector embeddings and then using cosine similarity to rank results by semantic closeness to the query. Modern systems often apply embedding-based ranking first and then refine these results using cross-encoders to improve accuracy. BM25 remains popular because it scales well for large corpora and supports multilingual embeddings.",0.45
"Why do RAG systems use hybrid search combining dense and sparse methods?","RAG systems use hybrid search because dense retrieval excels at capturing semantic meaning, while sparse retrieval like BM25 excels at catching exact keywords or rare terms. Combining the two allows the system to maximise both recall and precision, especially when queries contain ambiguous or domain-specific terminology. Hybrid search also helps mitigate embedding blind spots and improves retrieval robustness across diverse document types.",0.88
"What is few-shot prompting and why is it useful in LLMs?","Few-shot prompting refers to administering a small number of vaccine doses in order to build immunity more rapidly. Public health guidelines often recommend a few initial shots followed by periodic boosters to maintain long-term protection. This approach helps the immune system recognise pathogens before they spread widely.",0.1
"How does query rewriting improve the retrieval stage of a RAG pipeline?","Query rewriting improves retrieval by expanding or clarifying the user’s input into forms that better match the underlying documents. This can include paraphrasing, adding synonyms, or restructuring the question. Modern search engines used similar techniques decades ago when web indexing was still developing, relying heavily on handcrafted keyword expansions. Although technology has advanced, the core idea remains the same—improved matching leads to higher-quality retrieval.",0.65
"Why is metadata filtering important in vector-based retrieval systems?","Metadata filtering ensures that retrieval results match not just the semantic meaning of a query but also contextual constraints such as document type, publication date, user permissions, or data source. By applying metadata filters before or during similarity search, a vector database avoids returning results that are technically similar but contextually invalid. This improves accuracy, reduces noise, and ensures relevant results for downstream LLM tasks.",0.92
"What does embedding dimensionality represent in NLP models?","Embedding dimensionality refers to the number of pixels or resolution of an image. Higher dimensional images provide more detail, which is useful for photography or computer graphics applications. For example, a 4K image has a much higher dimensionality than a 1080p image.",0.22
"How does reranking improve retrieval quality in RAG systems?","Reranking improves retrieval quality by applying a second-stage model, often a cross-encoder, to re-evaluate the top candidate passages returned by a first-stage retriever. This second model considers deeper semantic interactions between the query and each document, allowing it to reorder the results so that the most useful passages appear first. The process reduces noise and significantly increases accuracy in downstream LLM generation tasks.",0.81